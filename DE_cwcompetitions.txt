<script class="kaggle-component" nonce="8Nktv6qeYC96hXVswpVT3A==">
 var Kaggle=window. Kaggle||{};Kaggle. State=Kaggle. State||[];Kaggle. State. push({"title":"Competitions","subtitle":"Find challenges for every interest level","imageUrl":"","mimeType":"text/html","pageContent":"hr width=100% align=left! --Types of Competitions--h3 id=types-of-competitionsTypes of Competitions/h3pKaggle Competitions are designed to provide challenges for competitors at all different stages of their machine learning careers.  As a result, they are very diverse, with a range of broad types. /p    h4 id=featuredFeatured/h4    pFeatured competitions are the types of competitions that Kaggle is probably best known for.  These are full-scale machine learning challenges which pose difficult, generally commercially-purposed prediction problems.  For example, past featured competitions have included:/p    ul style=list-style-type:disc        li            pa href= Claim Prediction Challenge/a - Use customers shopping history to predict which insurance policy they purchase/p        /li        li            pa href= Toxic Comment Classification Challenge/a - Predict the existence and type of toxic comments on Wikipedia/p        /li        li            pa href= Prize/a - Build a machine learning algorithm that can challenge Zestimates, the Zillow real estate price estimation algorithm/p        /li    /ul    pFeatured competitions attract some of the most formidable experts, and offer prize pools going as high as a million dollars.  However, they remain accessible to anyone and everyone.  Whether youre an expert in the field or a complete novice, featured competitions are a valuable opportunity to learn skills and techniques from the very best in the field. /p    h4 id=researchResearch/h4    pResearch competitions are another common type of competition on Kaggle.  Research competitions feature problems which are more experimental than featured competition problems.  For example, some past research competitions have included:/p    ul style=list-style-type:disc        li            pa href= Landmark Retrieval Challenge/a - Given an image, can you find all the same landmarks in a dataset? /p        /li        li            pa href= Whale Recognition/a - Identify endangered right whales in aerial photographs/p        /li        li            pa href= Scale Hierarchical Text Classification/a - Classify Wikipedia documents into one of ~300,000 categories/p        /li    /ul    pResearch competitions do not usually offer prizes or points due to their experimental nature.  But they offer an opportunity to work on problems which may not have a clean or easy solution and which are integral to a specific domain or area in a slightly less competitive environment. /p    h4 id=getting-startedGetting Started/h4    pGetting Started competitions are the easiest, most approachable competitions on Kaggle.  These are semi-permanent competitions that are meant to be used by new users just getting their foot in the door in the field of machine learning.  They offer no prizes or points.  Because of their long-running nature, Getting Started competitions are perhaps the most heavily tutorialized problems in machine learning - just what a newcomer needs to get started! /p    ul style=list-style-type:disc        li            pa href= Recognizer/a/p        /li        li            pa href= Machine Learning from Disaster/a  - Predict survival on the Titanic/p        /li        li            pa href= Prices: Advanced Regression Techniques/a/p        /li    /ul    pGetting Started competitions have two-month rolling leaderboards.  Once a submission is more than two months old, it is automatically invalidated and no longer counts towards the leaderboard.  Similarly, your team will drop from the leaderboard if all its submissions are older than two months.  This gives new Kagglers the opportunity to see how their scores stack up against a cohort of competitors, rather than many tens of thousands of users.  If your team is removed from a Getting Started competition due to the rolling expiry and wishes to rejoin, creating a new submission will cause it to show again on the leaderboard. /p    pAdditionally, the a href= Learn/a platform has several tracks for beginners interested in free hands-on data science learning from pandas to deep learning.  Lessons within a track are separated into easily digestible chunks and contain Notebook exercises for you to practise building models and new techniques.  Youll learn all the skills you need to dive into Kaggle Competitions. /p    h4 id=playgroundPlayground/h4    pPlayground competitions are a for fun type of Kaggle competition that is one step above Getting Started in difficulty.  These are competitions which often provide relatively simple machine learning tasks, and are similarly targeted at newcomers or Kagglers interested in practicing a new type of problem in a lower-stakes setting.  Prizes range from kudos to small cash prizes.  Some examples of Playground competitions are:/p    ul style=list-style-type:disc        li            pa href= versus Cats/a - Create an algorithm to distinguish dogs from cats/p        /li        li            pa href= Classification/a - Can you see the random forest for the leaves? /p        /li        li            pa href= York City Taxi Trip Duration/a - Share code and data to improve ride time predictions/p        /li    /ulhr width=100% align=left! --Competition Formats--h3 id=competition-formatsCompetition Formats/h3pIn addition to the different categories of competitions (e. g. , featured), there are also a handful of different formats competitions are run in. /p    h4 id=simple-competitionsSimple Competitions/h4    pSimple (or classic) competitions are those which follow the standard Kaggle format.  In a simple competition, users can access the complete datasets at the beginning of the competition, after accepting the competitions rules.  As a competitor you will download the data, build models on it locally or in a href= generate a prediction file, then upload your predictions as a submission on Kaggle.  By far most competitions on Kaggle follow this format. /p    pOne example of a simple competition is the a href= Seguro Safe Driver Prediction Competition/a. /p    h4 id=two-stage-competitionsTwo-stage Competitions/h4    pIn two-stage competitions the challenge is split into two parts: Stage 1 and Stage 2, with the second stage building on the results teams achieved in Stage 1.  Stage 2 involves a new test dataset that is released at the start of the stage.  Eligibility for Stage 2 typically requires making a submission in Stage 1.  In two-stage competitions, its especially important to read and understand the competitions specific rules and timeline. /p    pOne example of such a competition is the a href= Conservancy Fisheries Monitoring Competition/a. /p    h4 id=notebooks-only-competitionsCode Competitions/h4    pSome competitions are code competitions.  In these competitions all submissions are made from inside of a Kaggle Notebook, and it is not possible to upload submissions to the Competition directly. /p    pThese competitions have two attractive features.  The competition is more balanced, as all users have the same hardware allowances.  And the winning models tend to be far simpler than the winning models in other competitions, as they must be made to run within the compute constraints imposed by the platform. /p    pCode competitions are configured with their own unique constraints on the Notebooks you can submit.  These may be restricted by characteristics like: CPU or GPU runtime, ability to use external data, and access to the internet.  To learn the constraints you must adhere to, review the Requirements for that specific competition. /p    pAn example of a code competition is a href= Insincere Questions Classification/a. /p    h4 id=notebooks-only-FAQCode Competition FAQ/h4pstrongIm getting errors when submitting.  What should I do? /strong/pp style=padding-left: 30px;1.  Please see our page on a href= competition debugging/a for tips on understanding and preventing submission errors. /pp style=padding-left: 30px;1.  First youll need to write a Notebook which reads the Competitions dataset and makes predictions on the test set.  Specifically, have your Notebook write your predictions to a submission file, which is typically a submission. csv file, though some competitions have special formats.  See the competitions Evaluation page, or look for sample_submission. csv (or similar) in the Data page for more information on the expected name and format of your submission file. /pp style=padding-left: 30px;2.  Save a full version of your Notebook by clicking Save Version and selecting Save amp; Run All.  This saves your code, runs it, and creates a version of the code and output.  Once your save finishes, navigate to the Viewer page for your new Notebook Version. /pp style=padding-left: 30px;3.  In the Notebook Viewer, navigate to the Output section, find and select the submission file you created, and click the Submit button. /ppstrongCan I upload external data? /strong/ppSome competitions allow external data and some do not.  If a competition allows external data, you can attach it to your Notebook by adding it as a data source.  If a competition does not allow external data, attaching it to your Notebook will deactivate the Submit button on the associated saved version. /ppstrongWhat are the compute limits of Notebooks? /strong/ppThe compute limits of the Notebooks workers are subject to change.  You can view the site-wide memory, CPU, runtime limits, and other limits from the editor. /ppCode competitions come in many shapes and sizes, and will often impose limits specific to a competition.  You should view the competition description to understand if these limits are activated and what they are.  Example variations include:/pp style=padding-left: 30px;- Specific runtime limitsbr /- Specific limits that apply to Notebooks using GPUsbr /- Internet access allowed or disallowedbr /- External data allowed or disallowedbr /- Custom package installs allowed or disallowedbr /- Submission file naming expectations/ppstrongHow do I team up in a code competition? /strong/ppAll the competitions setup is the same as normal competitions, except that submissions are only made through Notebooks.  To team up, go to the Team tab and invite others. /ppstrongHow will winners be determined? /strong/ppIn some code competitions, winners will be determined by re-running selected submissionsrsquo; associated Notebooks on a private test set. /ppIn such competitions, you will create your models in Notebooks and make submissions based on the test set provided on the Data page.  You will make submissions from your Notebook using the above steps and select submissions for final judging from the ldquo;My Submissionsrdquo; page, in the same manner as a regular competition. /ppFollowing the competition deadline, your code will be rerun by Kaggle on a private test set that is not provided to you.  Your models score against this private test set will determine your ranking on the private leaderboard and final standing in the competition. /phr width=100% align=left! --Joining a Competition --h3 id=joining-a-competitionJoining a Competition/h3pKaggle runs a variety of different kinds of competitions, each featuring problems from different domains and having different difficulties.  Before you start, navigate to the a href= listing/a.  It lists all of the currently active competitions. /ppPublic competitions are viewable on Kaggle and appear in Kaggle search results.  Depending on the privacy and access set by the host, some competitions may be unavailble for you to see or join.  If a host set a competitions visibility to private, you would only see the competitions details if they shared a unique URL with you. /ppIf you click on a specific Competition in the listing, you will go to the Competitions homepage. /ppThe first element worth calling out is the Rules tab.  This contains the rules that govern your participation in the sponsors competition.  You must accept the competitions rules before downloading the data or making any submissions.  Its extremely important to read the rules before you start.  This is doubly true if you are a new user.  Users who do not abide by the rules may have their submissions invalidated at the end of the competition or banned from the platform.  So please make sure to read and understand the rules before choosing to participate. /ppIf anything is unclear or you have a question about participating, the competitions forums are the perfect place to ask. /ppThe information provided in the Overview tabs will vary from Competition to Competition.  Five elements which are almost always included and should be reviewed are the Description, Data, Evaluation, Timeline, amp; Prizes sections. /ppThe strongdescription/strong gives an introduction into the competitions objective and the sponsors goal in hosting it. /ppThe strongdata/strong tab is where you can download and learn more about the data used in the competition.  Youll use a training set to train models and a test set for which youll need to make your predictions.  In most cases, the data or a subset of it is also accessible in Notebooks. /ppThe strongevaluation/strong section describes how to format your submission file and how your submissions will be evaluated.  Each competition employs a metric that serves as the objective measure for how competitors are ranked on the leaderboard. /ppThe strongtimeline/strong has detailed information on the competition timeline.  Most Kaggle Competitions include, at a minimum, two deadlines: a rules acceptance deadline (after which point no new teams can join or merge in the competition), and a submission deadline (after which no new submissions will be accepted).  It is very, very important to keep these deadlines in mind. /ppThe strongprizes/strong section provides a breakdown of what prizes will be awarded to the winners, if prizes are relevant.  This may come in the form of monetary, swag, or other perks.  In addition to prizes, competitions may also award ranking points towards the Kaggle progression system.  This is shown on the Overview page. /ppReady to join?  If the competition allows anyone to join, you should be able to click Join and accept the competitions rules.  If the competition has restricted access, the host will share a private link with you that allows you to join. /ppOnce you have chosen a competition, read and accepted the rules, and made yourself aware of the competition deadlines, you are ready to submit! /phr width=100% align=left! --Forming a Team--h3 id=forming-a-teamForming a Team/h3pEveryone that competes in a Competition does so as a team.  A team is a group of one or more users who collaborate on the competition.  Joining a team of other users around the same level as you in machine learning is a great way to learn new things, combine your different approaches, and generally improve your overall score. /ppIts important to keep in mind that team size does not affect the limit on how many submissions you may make to a competition per day: whether you are a team of one or a team of five, you will have the same daily submission limit. /ppWhen you accept the rules and join a Competition, you automatically do so as part of a new team consisting solely of yourself.  You can then adjust your team settings in various ways by visiting the Team tab on the Competition page:/ppimg src= alt=/ppYou can perform a number of different team-related actions on this tab. /p    h4 id=types-of-team-membershipsTypes of Team Memberships/h4    pThere are two team membership statuses.  One person serves as the Team Leader.  They are the primary point of contact when we need to communicate with a team, and also have some additional team modification privileges (to be discussed shortly).  Every other person in the team is a Member. /p    pIf you are the Team Leader you will see a box next to every other team members name on the Team page that says Make Leader.  You may click on this at any time to designate someone else on your team the Team Leader. /p    h4 id=changing-your-team-nameChanging your Team Name/h4    pThe team name is distinct from the names of its members, even if the team only consists of a single person (yourself).  You can always change your team name to something custom, and other users will see that custom name when they visit the competition leaderboard.  Most teams customize their names! /p    pAnyone in the team can modify the team name by visiting the Team tab. /p    h4 id=merging-teamsMerging Teams/h4    pYou may invite another team to your team or, reciprocally, accept a merge request from another team.  If you propose a merger, the merger can be accepted or rejected by the Team Leader of the other team.  If you are proposed a merger, the Team Leader may choose to accept or reject it. /p    pThere are some limits on when you can merge teams:/p    ul style=list-style-type:disc        li            pMost competitions have a team merger deadline: a point in time by which all teams must be finalized.  No mergers may occur after this date/p        /li        li            pSome competitions specify a maximum team size; you will not be able to merge teams whose cumulative number of members exceeds this cap/p        /li        li            pYou will not be able to merge teams whose combined daily submission count exceeds the total submission limit to that date (daily limit x number of days). /p        /li    /ul    pAll of this can be managed through the Team tab. /p    h4 id=disbanding-a-teamDisbanding a Team/h4    pChoose your teammates wisely as only teams that have not made any submissions can be disbanded.  This can be done through the Team tab/phr width=100% align=left! --Making a Submission--h3 id=making-a-submissionMaking a Submission/h3pYou will need to submit your model predictions in order to receive a score and a leaderboard position in a Competition.  How you go about doing so depends on the format of the competition. /p! -- Link format of the competition to corresponding section -- pEither way, remember that your team is limited to a certain number of submissions per day.  This number is five, on average, but varies from competition to competition. /p    h4 id=leaderboardLeaderboard/h4    pOne of the most important aspects of Kaggle Competitions is the Leaderboard.  The Competition leaderboard has two parts. /p    pThe public leaderboard provides publicly visible submission scores based on a representative sample of the test data.  This leaderboard is visible throughout the competition. /p    pThe private leaderboard, by contrast, tracks model performance using the remainder of the test data.  The private leaderboard thus has final say on whose models are best, and hence, who the winners and losers of the Competition will be.  Which subset of data is calculated on the private leaderboard or a submissions performance on the private leaderboard is not released to users until the competition has been closed. /p    pMany users watch the public leaderboard closely, as breakthroughs in the competition are announced by score gains in the leaderboard.  These jumps in turn motivate other teams working on the competition in search of those advancements.  But its important to keep the public leaderboard in perspective.  Its very easy to overfit a model, creating something that performs very well on the public leaderboard, but very badly on the private one.  This is called a href=    pIn the event of an exact score tie, the tiebreaker is the team which submitted earlier.  Kaggle always uses full precision when determining rankings, not just the truncated precision shown on the Leaderboard. /p    h4 id=submitting-predictionsSubmitting Predictions/h4        h5 id=submitting-by-uploading-a-fileSubmitting by Uploading a File/h5        pFor most competitions, submitting predictions means uploading a set of predictions (known as a submission file) to Kaggle. /p        pAny competition which supports this submission style will have Submit Predictions and My Submissions buttons in the Competition homepage header. /p        pTo submit a new prediction use the Submit Prediction button.  This will open a modal that will allow you to upload your submission file.  We will attempt to score this file, then add it to My Submissions once it is done being processed. /p        pNote that to count, your submission must first pass processing.  If your submission fails during the processing step, it will not be counted and not receive a score; nor will it count against your daily submission limit.  If you encounter problems with your submission file, your best course of action is to ask for advice on the Competitions discussion forum. /p        pIf you click on the My Submissions tab you will see a list of every submission you have ever made to this competition.  You may also use this tab to select which submission file(s) to submit for scoring before the Competition closes.  Your final score and placement at the end of the competition will be whichever selected submission performed best on the private leaderboard.  If you do not select submission(s) to be scored before the competition closes, the platform will automatically select those which performed the highest on the public leaderboard, unless otherwise communicated in the competition. /p        h5 id=submitting-by-uploading-from-a-notebookSubmitting by Uploading from a Notebook/h5        pIn addition to our usual Competitions, Kaggle may also allow competition submissions from Kaggle Notebooks.  Notebooks are an interactive in-browser code editing environment; to learn more about them, see the documentation sections on a href=        pTo build a model, start by initializing a new Notebook with the Competition Dataset as a data source.  This is easily done by going to the Notebooks tab within a competitions page and then clicking New Notebook.  That competitions dataset will automatically be used as the data source.  New Notebooks will default as private but can be toggled to public or shared with individual users (for example, others on your team). /p        pBuild your model and test its performance using the interactive editor.  Once you are happy with your model, use it to generate a submission file within the Notebook, and write that submission file to disk in the default working directory (/kaggle/working).  Then click Save Version and select Save amp; Run All to build a new Notebook version using your code. /p        pOnce the new Notebook Version is done (it must run top-to-bottom within the Notebooks platform constraints), navigate to the Notebook Viewer page to see the execution results, then find and select your submission file in the Output section, and you should see a Submit button to submit it to the Competition. /phr width=100% align=left! -- Leakage --h3 id=leakageLeakage/h3    h4 id=what-is-leakageWhat is Leakage? /h4    pData Leakage is the presence of unexpected additional information in the training data, allowing a model or machine learning algorithm to make unrealistically good predictions. /p    pLeakage is a pervasive challenge in applied machine learning, causing models to over-represent their generalization error and often rendering them useless in the real world.  It can be caused by human or mechanical error, and can be intentional or unintentional in both cases. /p    pSome types of data leakage include:/p    ul style=list-style-type:disc        li            pLeaking test data into the training data/p        /li        li            pLeaking the correct prediction or ground truth into the test data/p        /li        li            pLeaking of information from the future into the past/p        /li        li            pRetaining proxies for removed variables a model is restricted from knowing/p        /li        li            pReversing of intentional obfuscation, randomization or anonymization/p        /li        li            pInclusion of data not present in the models operational environment/p        /li        li            pDistorting information from samples outside of scope of the models intended use/p        /li        li            pAny of the above present in third party data joined to the training set/p        /li    /ul    h4 id=examplesExamples/h4    pOne concrete example weve seen occurred in a dataset used to predict whether a patient had prostate cancer.  Hidden among hundreds of variables in the training data was a variable named PROSSURG.  It turned out this represented whether the patient had received prostate surgery, an incredibly predictive but out-of-scope value. /p    pThe resulting model was highly predictive of whether the patient had prostate cancer but was useless for making predictions on new patients. /p    pThis is an extreme example - many more instances of leakage occur in subtle and hard-to-detect ways.  An early Kaggle competition, Link Prediction for Social Networks, makes a good case study in this. /p    pThere was a sampling error in the script that created that dataset for the competition: a gt; sign instead of a gt;= sign meant that, when a candidate edge pair had a certain property, the edge pair was guaranteed to be true.  A team exploited this leakage to take second in the competition. /p    pFurthermore, the winning team won not by using the best machine-learned model, but by scraping the underlying true social network and then defeated anonymization of the nodes with a very clever methodology. /p    pOutside of Kaggle, weve heard war stories of models with leakage running in production systems for years before the bugs in the data creation or model training scripts were detected. /p    h4 id=leakage-in-competitionsLeakage in Competitions/h4    pLeakage is especially challenging in machine learning competitions.  In normal situations, leaked information is typically only used accidentally.  But in competitions, participants often find and intentionally exploit leakage where it is present. /p    pParticipants may also leverage external data sources to provide more information on the ground truth.  In fact, the concept of identifying and harnessing leakage has been openly addressed as one of three key aspects for winning data mining competitions (a href= paper/a). /p    pIdentifying leakage beforehand and correcting for it is an important part of improving the definition of a machine learning problem.  Many forms of leakage are subtle and are best detected by trying to extract features and train state-of-the-art models on the problem.  This means that there are no guarantees that competitions will launch free of leakage, especially for Research competitions (which have minimal checks on the underlying data prior to launch). /p    pWhen leakage is found in a competition, there are many ways that we can address it.  These may include:/p    ul style=list-style-type:disc        li            pLet the competition continue as is (especially if the leakage only has a small impact)/p        /li        li            pRemove the leakage from the set and relaunch the competition/p        /li        li            pGenerate a new test set that does not have the leakage present/p        /li    /ul    pUpdating the competitions isnt possible in all cases.  It would be better for the competition, the participants, and the hosts if leakage became public knowledge when it was discovered.  This would help remove leakage as a competitive advantage and give the host more flexibility in addressing the issue. /phr width=100% align=left! --Resources for Getting Started--h3 id=resources-for-getting-startedResources for Getting Started/h3    h4 id=getting-startedGetting Started/h4    ul style=list-style-type:disc        li            pThe Getting Started Competitions are specifically targeted at new users getting their feet wet with Kaggle and/or machine learning:/p            ul style=list-style-type:circle                li                    pBinary classification: a href= Machine Learning from Disaster/a/p                /li                li                    pRegression: a href= Prices: Advanced Regression Techniques/a/p                /li            /ul        /ul        ul style=list-style-type:disc            li                pThe a href= Learn/a platform has several tracks for beginners interested in free hands-on data science learning from pandas to deep learning.  Lessons within a track are separated into easily digestible chunks and contain Notebook exercises for you to practise building models and new techniques hands-on.  It is a great way to start deep diving into data science and quickly get familiar with the field! /p            /li            li                pa href= Kaggle has learned from almost 2MM machine learning models/a on Youtube.  This a href= talk by Kaggle founder Anthony Goldbloom lays out what Kaggle competitions are all about. /p            /li            li                pa href= to (almost) win at Kaggle/a on Youtube.  In this talk competitor Kiri Nichols summarizes the appeal of Competitions as a data science learner. /p            /li        /ul    h4 id=discussionDiscussion/h4    ul style=list-style-type:disc        li            pa href= Discussion/a: There are six general site Discussion Forums:/p        /li        ul style=list-style-type:circle            li                pa href= Forum/a: Events and topics specific to the Kaggle community/p            /li            li                pa href= Started/a: The first stop for questions and discussion for new Kagglers/p            /li            li                pa href= Feedback/a: Tell us what you love, hate, or wish for/p            /li            li                pa href= amp; Answers/a: Technical advice from other data scientists/p            /li            li                pa href= Requests for and discussion of open data/p            /li            li                pa href= Questions, answers, and requests related to a href= Learn courses/a/p            /li        /ul    /ul    ul style=list-style-type:disc        li            pCompetition Discussion Forums: No matter the competition you are participating in, you can count on plenty of active community members making posts to the forums.  If you get stuck on a particular aspect of the problem, Discussions are a great place to ask questions. /p        /li        li            pCompetition Notebooks: Similar to Discussions, Notebooks shared within a competition are an excellent source of Exploratory Data Analyses (EDAs) amp; basic starter models which can be forked and built upon for applied learning. /p        /li        li            pThe a href= Noobs Slack channel/a: This Slack channel is a popular watering hole for general banter among Kaggle ML practitioners from Novice to Grandmaster. /p        /li    /ul    h4 id=techniquesTechniques/h4    ul style=list-style-type:disc        li            pPublic, reproducible code examples in Notebooks are a great way to learn and put to practice new techniques.  Search for techniques in a href= by tag using the search syntax codetag:classification/code.  Fork Notebooks to make a copy of the code to modify and experiment with. /p        /li        li            pThe a href= Free Hunch/a blog.  No Free Hunch is a great way of keeping up with goings-on on Kaggle.  Many past Competitions winners have been interviewed about and presented their winning models on No Free Hunch.  Here are some examples of past winners interviews:/p        /li        ul style=list-style-type:circle            li                pa href= Right Whale Identification/a/p            /li            li                pa href= Market Basket Analysis, Winners Interview: 2nd place, Kazuki Onodera/a/p            /li            li                pa href= Sigma Financial Modeling Code Competition/a/p            /li        /ul    /ul    ul style=list-style-type:disc        li            pVarious a href= have been published on No Free Hunch:/p        /li        ul style=list-style-type:circle            li                pa href= Intuitive Introduction to Generative Adversarial Networks/a/p            /li            li                pa href= To Neural Networks/a/p            /li            li                pa href= Kaggle Master Explains Gradient Boosting/a/p            /li            li                pa href= Kagglers Guide to Model Stacking in Practice/a/p            /li        /ul    /ul    ul style=list-style-type:disc        li            pa href= Michailidis: How to become a Kaggle #1: An introduction to model stacking/a: In this Data Science Festival talk top Kaggler Marios Michailidis (Kasanova) explains model stacking, a key feature of winning competition models, in great detail. /p        /li        li            pa href= Grandmaster Panel/a: A panel QA from H2O World 2017 featuring some top Kagglers. /p        /li        li            pa href= to Win A Kaggle Competition - Learn From Top Kagglers/a: This Coursera course, put together by high-ranking Kagglers, going into great detail on the tools and techniques used by winning Competitions models. /p        /li    /ulhr width=100% align=left! --Cheating--h3 id=cheatingCheating/h3            pCheating is not taken lightly on Kaggle.  We monitor our  a href= account/a (the formal channel for reporting cheaters, or appealing a removal for cheating) during competitions.  We also spend a considerable amount of time at the close of each competition to review suspicious activity and remove people who have violated the rules from the leaderboard.  When we believe we have sufficient evidence, we take action through removal or possibly even an account ban.  /p            pWe also monitor and investigate moderation reports (plagiarism, voting rings, etc. ) throughout the week, and take action as appropriate, which includes removing medals as well as full-out blocking accounts. /p            pIf you believe you have evidence that suggests a team violated competition rules, please report it to the Competitions a href= account/a for a thorough investigation. /p","id":33336,"isPublished":true,"url":"docs/competitions","isDocPage":true,"allowUnsanitizedHtml":true});performance && performance. mark && performance. mark("CmsPageContainer. componentCouldBootstrap");
</script>
